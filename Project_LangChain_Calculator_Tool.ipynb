{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP13rDAGHau2bGxayQRbjSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aimy99/Project-Langchain-Calculator-Tool/blob/main/Project_LangChain_Calculator_Tool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PIAIC Quarter 3 - Project 03: 'LangChain Function/Tool Calling Calculator'**\n",
        "\n",
        "*Developed by Aiman Baquar*\n",
        "\n",
        "### **Overview:**\n",
        "\n",
        "The LangChain Function/Tool Calling Calculator uses the Google Gemini model to perform real-time calculations through a conversational interface. By integrating LangChain's tool-calling feature, it dynamically responds to user queries and handles arithmetic tasks efficiently.\n",
        "\n",
        "\n",
        "### **Technology Stack:**\n",
        "\n",
        "*   **LangChain** (Integration): Acts as the bridge connecting the Google Gemini Flash model to custom tools like the calculator.\n",
        "\n",
        "*   **Google Gemini** (AI Model): Powers natural language understanding and generates responses, invoking the calculator tool as needed to compute results.\n",
        "\n",
        "*  **Python** (Programming Language): Implements the core logic for the calculator and integrates it with LangChain for smooth functionality.\n",
        "\n",
        "*   **Google Colab** (Environment): Built and executed within a Google Colab notebook, leveraging cloud-based resources for enhanced scalability.\n",
        "\n",
        "### **Outcome:**\n",
        "\n",
        "A fully functional conversational calculator that processes arithmetic queries and performs real-time calculations. The tool efficiently computes mathematical expressions, delivering accurate and timely results in response to user input.\n",
        "\n",
        "### **Use Cases:**\n",
        "\n",
        "*  Educational Tools: Assists students in solving math problems interactively and in real-time.\n",
        "\n",
        "\n",
        "*  Customer Support: Can be embedded into support bots to quickly handle customer queries involving calculations.\n",
        "\n",
        "\n",
        "*  E-commerce: Facilitates calculations for discounts, taxes, shipping costs, and other related operations.\n",
        "\n",
        "\n",
        "*  Finance: Computes financial metrics such as loan interest, ROI, or currency exchange rates.\n",
        "\n",
        "\n",
        "*  Healthcare: Performs medical calculations like BMI or dosage conversions for healthcare professionals.\n",
        "\n",
        "\n",
        "*  Productivity Apps: Seamlessly integrated into personal assistant apps to handle calculations on-the-go."
      ],
      "metadata": {
        "id": "SIzahpKPtbJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing Langchain\n",
        "!pip install -q -U langchain langchain_community langchain-google-genai"
      ],
      "metadata": {
        "id": "6VhPIijXt6uC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d50cb20-e186-4b03-de1e-83543734874e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.5 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m2.4/2.5 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing userdata from Google Colab to securely store API keys\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "gemini_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ['GOOGLE_API_KEY'] = 'GOOGLE_API_KEY'\n",
        "\n",
        "# Importing GoogleGenAIChat Class from Google Gemini Langchain module\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Optimizing model features\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    api_key= gemini_api_key,\n",
        "    temperature=0.7,\n",
        "    max_tokens= 300,\n",
        "    timeout=None,\n",
        "    max_retries= 6,\n",
        ")"
      ],
      "metadata": {
        "id": "lEEKCEeaNmS_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai_msg= llm.invoke(\"What is Tool Calling?\")\n",
        "print(ai_msg.content)"
      ],
      "metadata": {
        "id": "3NwvgWyANruv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445b2159-a2fa-4e76-9084-3b802bc93113"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool calling, also sometimes referred to as **function calling** or **API calling**, is a powerful capability of large language models (LLMs) like GPT-4, Claude, and others. It allows the LLM to interact with external tools or APIs to perform actions, gather information, or extend its functionality beyond its training data.\n",
            "\n",
            "Here's a breakdown of what tool calling is and how it works:\n",
            "\n",
            "**Core Idea:**\n",
            "\n",
            "Instead of just generating text, the LLM can now generate structured data that specifies:\n",
            "\n",
            "1. **Which tool to use:** It identifies the appropriate tool or API based on the user's request.\n",
            "2. **What parameters to pass:** It determines the necessary inputs for the chosen tool.\n",
            "\n",
            "This structured data is then passed to an external system (the \"tool\") which executes the action and returns the result. The LLM can then use this result to inform its next response to the user.\n",
            "\n",
            "**How it Works (Simplified):**\n",
            "\n",
            "1. **User Input:** The user provides a prompt or request (e.g., \"What's the weather in London?\" or \"Send an email to John about the meeting\").\n",
            "2. **LLM Analysis:** The LLM analyzes the user's input and determines that it needs an external tool to fulfill the request (e.g., a weather API or an email sending API).\n",
            "3. **Tool Selection & Parameter Generation:** The LLM generates structured data that specifies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Integrate the calculator with LangChain as a tool\n",
        "from langchain.tools import Tool\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def subtract(a: int, b: int) -> int:\n",
        "    \"\"\"Subtract a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a - b\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "@tool\n",
        "def divide(a: int, b: int) -> int:\n",
        "    \"\"\"Divide a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a / b\n",
        "\n",
        "llm_with_tools = llm.bind_tools([multiply, add, subtract, divide])"
      ],
      "metadata": {
        "id": "f0gzb0tmNu9E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools_list=[add, subtract, multiply, divide]\n",
        "model_with_tools = llm.bind_tools(tools_list)"
      ],
      "metadata": {
        "id": "EhTv-S5ON2u7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm_with_tools.invoke(\"Hey how are you!\")\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "F092yye4N5pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d1a04f4-4bc0-4bf2-9c35-b96d844e2a95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm doing great! Ready to perform some calculations. How can I help?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "# Example tool for addition\n",
        "def add_numbers(a, b):\n",
        "    return a + b\n",
        "\n",
        "math_tool = Tool(\n",
        "    name=\"AdditionTool\",\n",
        "    func=lambda x: f\"The result is: {add_numbers(*map(int, x.split()))}\",\n",
        "    description=\"Adds two numbers. Input should be two integers separated by a space.\"\n",
        ")"
      ],
      "metadata": {
        "id": "tAqmwtNqN8-W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the LLM with tool-calling capabilities\n",
        "from langchain.agents import initialize_agent, AgentType, AgentExecutor\n",
        "\n",
        "# The calculator tool will handle basic arithmetic operations\n",
        "class Calculator:\n",
        "    def calculate(self, expression: str) -> str:\n",
        "        try:\n",
        "            # Use Python's eval to compute the result safely\n",
        "            result = eval(expression, {\"__builtins__\": None}, {})\n",
        "            return str(result)\n",
        "        except Exception as e:\n",
        "            return f\"Error: {e}\"\n"
      ],
      "metadata": {
        "id": "vD6VGJHKOBtn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the Calculator class\n",
        "calculator = Calculator()\n",
        "\n",
        "# Wrap the Calculator within a Tool object\n",
        "# Provide a name, description and the function to be called\n",
        "calculator_tool = Tool(\n",
        "    name=\"Calculator\",\n",
        "    func=calculator.calculate,\n",
        "    description=\"Useful for when you need to answer questions about math.\"\n",
        ")\n",
        "\n",
        "tools = [calculator_tool] # Use the Tool object in the tools list"
      ],
      "metadata": {
        "id": "haD52mm5OGth"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Initialize the Agent for Tool Calling\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "zKhPGHl3OKIT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Query the agent\n",
        "response1 = agent.run(\"What is 10 - 20 + 15 x 10 / 2 ?\")  # Uses the tool\n",
        "print(response1)"
      ],
      "metadata": {
        "id": "OyM8FoziOM8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08844270-27b3-4d10-ad2b-da4ccb29bff7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to evaluate the expression 10 - 20 + 15 x 10 / 2 using the order of operations (PEMDAS/BODMAS). Multiplication and division have higher precedence than addition and subtraction, and are evaluated from left to right.\n",
            "Action: Calculator\n",
            "Action Input: 15 * 10 / 2\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m75.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mNow I have 10 - 20 + 75. I will perform the subtraction and addition from left to right.\n",
            "Action: Calculator\n",
            "Action Input: 10 - 20\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m-10\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mNow I have -10 + 75.\n",
            "Action: Calculator\n",
            "Action Input: -10 + 75\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m65\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 65\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "65\n"
          ]
        }
      ]
    }
  ]
}